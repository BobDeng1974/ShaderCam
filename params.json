{"name":"Shader Camera","tagline":"Demo app to discuss rendering camera frame using OpenGL ES","body":"##Shader Camera\r\nBy [LittleCheeseCake](http://littlecheesecake.me)\r\n\r\nOccasionally I receives emails asking how to render Camera Frame using OpenGL ES on Android. I lazily used some codes from an open source project [InstaCam](https://github.com/harism/android_instacam) without fully understand until recently I reviewed some fundamentals of OpenGL ES and re-impelemented a demo app for camera frame rendering using shaders. This post is to discuss some key aspects in the implementation and share the demo codes.\r\n\r\n###CameraRenderer\r\nDrawing using OpenGL is implemented by rendering on GLSurfaceView. The common approach is subclass the GLSurfaceView and implements the GLSurfaceView.Renderer. The rendering tasks are performed by implementing the interface.\r\n\r\n```java\r\npublic class CameraRenderer extends GLSurfaceView implements \r\n\t\t\t\t\t\t\t\tGLSurfaceView.Renderer, \r\n\t\t\t\t\t\t\t\tSurfaceTexture.OnFrameAvailableListener{\r\n\t@Override\r\n\tpublic synchronized void onSurfaceCreated(GL10 gl, EGLConfig config)\r\n\t{\r\n\t\t...\r\n\t\t//compile shader here\r\n\t}\r\n\t\r\n\t@Override\r\n\tpublic synchronized void onSurfaceChanged(GL10 gl, int width, int height) {\r\n\t   ...\r\n\t   //open camera and start preview here\r\n\t}\r\n\t\r\n\t@Override\r\n\tpublic synchronized void onDrawFrame(GL10 gl) {\r\n\t    ...\r\n\t    //draw frame as required\r\n\t}\r\n\t\r\n}\r\n```\r\n\r\n###SurfaceTexture\r\nSurfaceTexture Interface provided by Android SDK (API Level 11+) has made our life much easier when dealing with image streaming either from Camera or MediaPlayer. SurfaceTexture is bound with an OpenGL Texture id at its instantiate (mCameraTexture is discussed later, which generates OpenGL texture handle):\r\n\r\n```java\r\n@Override\r\npublic synchronized void onSurfaceChanged(GL10 gl, int width, int height) {\r\n    ...\r\n    SurfaceTexture mSurfaceTexture = new SurfaceTexture(mCameraTexture.getTextureId());\r\n    ...\r\n}\r\n\r\n```\r\nListeners can be registered to SurfaceTexture.setOnFrameAvailable to make updates whenever a new frame is streamed in. Here the camera renderer is registered to listening for the updates, whenever a new frame is streamed in, the renderer is required to draw a new frame on the surface. Use mSurfaceTexture.updateTexImage() to query the most recent frame on the stream.\r\n\r\n```java\r\n@Override\r\npublic synchronized void onSurfaceChanged(GL10 gl, int width, int height) {\r\n    ...\r\n    mSurfaceTexture.setOnFrameAvailableListener(this);\r\n    ...\r\n}\r\n\r\n...\r\n\r\n@Override\r\npublic synchronized void onFrameAvailable(SurfaceTexture surfaceTexture)\r\n{\r\n    //request the renderer to draw frame when new frame available\r\n\tupdateTexture = true;\r\n\trequestRender();\r\n}\r\n\r\n...\r\n\r\n@Override\r\npublic synchronized void onDrawFrame(GL10 gl) {\r\n    ...\r\n\t//render the texture to FBO if new frame is available, double check\r\n\tif(updateTexture){\r\n\t\tmSurfaceTexture.updateTexImage();\r\n\t\t...\r\n\t}\r\n}\r\n```\r\nThe texture updated by SurfaceTexture can only be bound to GL_TEXTURE_EXTERNAL_OES target rather than the GL_TEXTURE_2D target. Therefore a texture handle generated by the mCameraTexture object as mentioned above using the following implementation (bind with GLES11Ext.GL_TEXTURE_EXTERNAL_OES):\r\n\r\n```java\r\npublic class OESTexture {\r\n\t...\r\n\r\n\tpublic void init(){\r\n\t\tint[] mTextureHandles = new int[1];\r\n\t\tGLES20.glGenTextures(1, mTextureHandles, 0);\r\n\t\tmTextureHandle = mTextureHandles[0];\r\n\r\n\t\tGLES20.glBindTexture(GLES11Ext.GL_TEXTURE_EXTERNAL_OES, mTextureHandles[0]);\r\n\t\t...\r\n\r\n\t}\r\n}\r\n```\r\nIn the fragment shader when the texture is binded, the first line has to be inserted:\r\n\r\n```c\r\n#extension GL_OES_EGL_image_external : require\r\n\r\nprecision mediump float;\r\n\r\nuniform samplerExternalOES sTexture;\r\nvarying vec2 vTextureCoord;\r\n\r\nvoid main(){\r\n\tgl_FragColor = texture2D(sTexture, vTextureCoord);\r\n}\r\n```\r\n\r\n###Draw Screen Quad\r\nUsing shaders, a simple screen quad can be easily drawn.\r\n\r\n```java\r\nprivate void init(){\r\n\t//Create full scene quad buffer\r\n\tfinal byte FULL_QUAD_COORDS[] = {-1, 1, -1, -1, 1, 1, 1, -1};\r\n\tmFullQuadVertices = ByteBuffer.allocateDirect(4 * 2);\r\n\tmFullQuadVertices.put(FULL_QUAD_COORDS).position(0);\r\n\r\n\t...\r\n}\r\n\r\n...\r\nprivate void renderQuad(int aPosition){\r\n\tGLES20.glVertexAttribPointer(aPosition, 2, GLES20.GL_BYTE, false, 0, mFullQuadVertices);\r\n\tGLES20.glEnableVertexAttribArray(aPosition);\r\n\tGLES20.glDrawArrays(GLES20.GL_TRIANGLE_STRIP, 0, 4);\r\n}\r\n```\r\n\r\nThree issues are considered here \r\n\r\n1. A transformation matrix is queried using mSurfaceTexture.getTransformMatrix(float[]). This matrix transforms traditional 2D OpenGL ES texture coordinate column vectors of the form (s, t, 0, 1) where s and t are on the inclusive interval [0, 1] to the proper sampling location in the streamed texture. \r\n\r\n2. The orientation change of the phone has effect on the Surface dimension change (Height and Width swapped) but has no effect on the camera size (Width and Height remains as Width > Height all the time). This should be considered using an orientation matrix passed to the shader to adjust the orientation of the frame whenever the phone's orientation changes.\r\n\r\n3. The screen dimension (SurfaceView dimension and the camera frame dimension might not be the same, to maintain a proper w/h ratio, a scaling factor should be passed to the shader to resize the screen quad.\r\n\r\nThe codes below are the passing of the three parameters to the shader. Noted that uTransformM updated every frame as required, uOrientationM updated whenever the orientation of the phone changes, and ratios updated also when the orientation of the phone changes since the w/h ratio changes when their actual values change. The later two are updated in the onSurfaceChanged(GL10, int width, int height) method. \r\n\r\n```java\r\n@Override\r\npublic synchronized void onDrawFrame(GL10 gl) {\r\n    ...\r\n    int uTransformM = mOffscreenShader.getHandle(\"uTransformM\");\r\n\tint uOrientationM = mOffscreenShader.getHandle(\"uOrientationM\");\r\n\tint uRatioV = mOffscreenShader.getHandle(\"ratios\");\r\n\r\n\tGLES20.glUniformMatrix4fv(uTransformM, 1, false, mTransformM, 0);\r\n\tGLES20.glUniformMatrix4fv(uOrientationM, 1, false, mOrientationM, 0);\r\n\tGLES20.glUniform2fv(uRatioV, 1, mRatio, 0);\r\n\t...\r\n}\r\n```\r\n\r\nIn the vertex shader, uTransformM, uOrientationM and ratios together do some work to make sure the frame texture coordinate fit into the phone window:\r\n\r\n```c\r\nuniform mat4 uTransformM;\r\nuniform mat4 uOrientationM;\r\nuniform vec2 ratios;\r\nattribute vec2 aPosition;\r\n\r\nvarying vec2 vTextureCoord;\r\n\r\nvoid main(){\r\n\tgl_Position = vec4(aPosition, 0.0, 1.0);\r\n\tvTextureCoord = (uTransformM * ((uOrientationM * gl_Position + 1.0)*0.5)).xy;\r\n\tgl_Position.xy *= ratios;\r\n}\r\n```\r\n\r\n###Closure\r\nSome details are not covered in the post. It might be confusing by looking at the code fragments above. Here what I want to do is to take note of the critical steps in my implementation for my own record. I think it will be much helpful to go through the complete implementation of the [demo app](https://github.com/yulu/ShaderCam) (which is quite concise, only a few hundered lines of codes). What will be more interesting? Try to replace the fragment shader with some funny shaders in [Instagram_Filter](https://github.com/yulu/Instagram_Filter) and [ShaderFilter](https://github.com/yulu/ShaderFilter), to see the interesting filter applied real-time on camera view.\r\n\r\n![manga](https://dl.dropboxusercontent.com/spa/pv9m61pztxstay5/manga.png)\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}